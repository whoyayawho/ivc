# IVC (혁신비전센터) 소개

> **"센서가 공간을 스캔하는 것을 넘어, 공간을 이해하게 만들자"**

---

## 📌 IVC 개요

### 에스오에스랩(SOSLAB) 배경

에스오에스랩은 **솔리드 스테이트 라이다**를 설계하고 제조하는 기업으로, **3D 비전 센서 분야의 하드웨어 전문성**을 보유하고 있습니다. 오랜 기간 축적된 라이다 기술력을 바탕으로, 단순한 센서 제조를 넘어 혁신적인 솔루션을 개발하고자 합니다.

### IVC(Innovation Vision Center) 설립

**IVC(혁신비전센터)** 는 2025년에 설립된 에스오에스랩의 신규 혁신 조직입니다. IVC는 에스오에스랩의 미래 먹거리를 발굴하고, 차세대 기술 트렌드를 선도하기 위해 만들어졌습니다.

**핵심 통찰**
단순히 공간을 스캔하는 센서 기술에서 벗어나, **공간을 이해하는 지능형 플랫폼**을 개발하고자 합니다.

**차별화 전략**
라이다 단일 센서가 아닌, **멀티모달 센서 융합(LiDAR + RGB/열화상 카메라 + IMU 등)** 과 **AI 기반 공간지능 플랫폼**을 결합하여 하드웨어와 소프트웨어를 통합한 완전한 솔루션을 제공합니다.

### 핵심 비전

**"Spatial AI로 Physical AI를 완성한다"**

- **멀티모달 센서 기반 공간지능(Spatial AI) 플랫폼** 개발
- **Physical AI 시대**를 대비한 기술 리더십 확보
- 다양한 센서(LiDAR, RGB/열화상 카메라, IMU)를 융합하여 공간을 **종합적으로 이해**
- 공간 정보를 Physical AI 시스템이 이해할 수 있는 형태로 변환하는 **핵심 인터페이스** 제공

> **Physical AI**가 "사람처럼 움직이는 것"에 집중한다면,
> **Spatial AI**는 "사람처럼 보고, 생각하고, 판단하는 것"에 집중합니다.

### 핵심 역량

- 멀티모달 센서 융합 기술
- 공간지능(Spatial AI) 플랫폼
- LLM 기반 자율 에이전트 시스템
- 3D 재구성 및 시각화

### 주요 프로젝트

- AI 서비스 에이전트 ✅
- 3D 객체 감지/추적 ✅
- 무인 순찰 로봇 시스템 🚧
- 무인 리테일 시스템 📋

---

## 🔬 핵심 기술: SPADI (공간지능 플랫폼)

### 기술 개요

**SPADI (Spatial-Physical Agentic Device Interface)**

멀티모달 센서 융합을 통해 3D 공간을 인지하고, AI로 의미를 이해하며, Physical AI 시스템에 행동 명령을 전달하는 **완전한 공간지능 파이프라인**입니다.

**핵심 구성**

- **데이터 수집**: 멀티모달 센서 (LiDAR + RGB/열화상 카메라 + IMU)
- **실시간 처리**: NVIDIA Jetson Thor 플랫폼
- **지능형 분석**: AI 기반 공간 재구성/이해/추론 (LLM + 컴퓨터 비전 + 딥러닝)

### 3가지 핵심 기술

#### 1. Spatial Reconstruction (공간 재구성)

멀티모달 센서 융합을 통해 현실 공간을 고정밀 3D로 재구성하고, AI 학습을 위한 사실적 시뮬레이션 환경을 생성합니다.

- 멀티모달 센서 융합 (LiDAR + RGB/열화상 카메라 + IMU, 캘리브레이션)
- SLAM 기반 정확한 위치 추정 및 기하학적 정보 추출
- 3D Gaussian Splatting (실시간 사실적 렌더링)
- NVIDIA Isaac Sim 및 Omniverse 통합 (디지털 트윈 생성)
- Real2Sim 파이프라인 (실제 환경 → 시뮬레이션 자동 변환)

#### 2. Spatial Understanding (공간 이해)

재구성된 3D 공간에 의미론적 맥락을 부여하여, 객체가 무엇이고 어디에 정확히 위치하는지 파악합니다.

- 고정밀 객체 감지 (YOLOv8, SAM2)
- 사람 포즈 및 제스처 인식 (MediaPipe)
- 2D-to-3D 투영 (LiDAR 포인트 클라우드 기반 3D 위치 매핑)
- 다중 객체 추적 (Kalman Filter, Hungarian Algorithm, ID 할당)
- 의미론적 매핑 (객체 분류, 공간 관계 분석, 이상 감지)
- 하드웨어 가속 (Isaac ROS 기반 실시간 처리)

#### 3. Spatial Reasoning (공간 추론)

자연어 명령과 공간 정보를 기반으로 상황을 이해하고 자율적으로 의사결정 및 행동을 수행합니다.

- 자연어 명령 처리 (멀티모달 LLM, Transformer Engine)
- 시각-언어 융합 처리 (카메라 영상 + 자연어 명령 통합)
- 멀티 에이전트 AI 아키텍처 (Triage → Navigation → Execution)
- 컨텍스트 기반 자율 의사결정 (로봇 상태, 환경 조건, 작업 이력, 공간 제약)
- 행동 계획 수립 및 Physical AI 시스템 실행 명령 생성
- 동적 환경 변화에 대한 실시간 대응

### 멀티모달 센서 융합의 장점

**단일 센서 한계 극복**

- 카메라만 사용: 조도 변화에 취약, 3D 정보 부족
- LiDAR만 사용: 색상/질감 정보 부족, 세밀한 객체 인식 한계
- 열화상만 사용: 해상도 낮음, 환경 맥락 파악 어려움

**멀티모달 융합 효과**

- **동적 환경 변화** 대응: 조도, 날씨, 시간대 변화에도 안정적 인지
- **종합적 공간 이해**: 언어적 명령 + 비언어적 맥락(표정, 움직임, 주변 상황) 통합
- **정밀한 객체 인식**: 3D 위치 + 색상/질감 + 온도 정보 결합
- **강건한 추적**: 센서 간 상호 보완을 통한 신뢰성 향상

### 기술 로드맵

**1단계 (2025): 멀티모달 센서 모듈**

- 목표: 멀티모달 센서 융합 데이터 출력
- 핵심 구성: LiDAR + RGB/열화상 카메라 + IMU 통합 센서
- 기술 개발:
  - NVIDIA Jetson Thor 플랫폼 통합
  - 센서 융합 알고리즘 개발
  - ROS2 기반 데이터 출력 파이프라인

**2단계 (2026): Plug-and-Play 자율주행 모듈**

- 목표: 다양한 로봇 플랫폼에 즉시 장착 가능한 자율주행 솔루션
- 핵심 기능:
  - 4족, 2족, 바퀴형 로봇 범용 호환 시스템
  - LLM 기반 자연어 명령 처리
  - Isaac ROS 자율주행 스택 통합
  - 클라우드 연동 및 OTA 업데이트

**3단계 (2027-2028): 완전한 공간지능 플랫폼**

- 목표: Spatial AI 기반 고도화된 공간 이해 및 의사결정
- 핵심 기능:
  - Real2Sim 기술 완성
  - Gaussian Splatting 실시간 최적화
  - Semantic Mapping 고도화
  - AI 에이전트 시스템
  - NVIDIA Omniverse 완전 통합

---

## 🚀 진행 중인 프로젝트

### ✅ 구현 완료 프로젝트

#### 1. AI Service Agent (카페 서비스 시스템)

**멀티 에이전트 기반 무인 카페 고객 서비스 시스템**

- **기술 스택**: OpenAI GPT-4.1, Streamlit, ROS2
- **주요 기능**:
  - 멀티 에이전트 시스템 (Triage, Order, Service, Conversation)
  - LLM 기반 상황 판단 및 자율 행동
  - 음성 입출력 (OpenAI STT/TTS)
  - 실시간 스트리밍 AI 서비스
  - 장바구니 관리 및 멤버십 연동
- **특징**: 단순 명령 수행을 넘어 맥락을 이해하고 능동적으로 응대

#### 2. 3D Human Detection & Tracking System

**멀티모달 센서 융합 기반 실시간 사람 감지 및 추적 시스템**

- **기술 스택**: YOLOv8, SAM2, MediaPipe, ROS2
- **센서 융합**: LiDAR + RGB 카메라
- **주요 기능**:
  - 객체 감지 및 인스턴스 세그멘테이션
  - 33개 랜드마크 기반 스켈레톤 감지
  - Kalman Filter 기반 다중 객체 추적
  - 3D 포인트 클라우드 처리
  - RViz2 3D 시각화
- **성능**: 실시간 처리, 고정밀 추적, 제스처 인식

---

### 🚧 수행 중인 과제

#### 4족 로봇 탑재형 멀티모달 센서 및 공간지능 통합 시스템 (정부 과제)

**과제명**: 4족 로봇 탑재형 고성능 멀티모달 센서 및 공간지능 통합 시스템 개발과 이를 활용한 무인 경계/순찰 실증

**기간**: 2025 ~ 2026 (2차년도)

**핵심 기술**

1. **다관절 짐벌 기반 멀티모달 센서 모듈**

   - LiDAR + RGB 카메라 + 열화상 카메라 + IMU
   - 센서 캘리브레이션 및 시점 동기화
   - 멀티모달 융합 데이터 생성

2. **공간지능 기반 에이전트 시스템**

   - SLAM 기반 3D 지도 생성
   - 자율주행 알고리즘
   - 객체 탐지 및 추적

3. **3D Gaussian Splatting 기반 고정밀 맵핑**
   - 사실적 3D 모델 재구성
   - 실시간 상황 인지 및 시각화
   - LLM 기반 자연어 이해

**실증 내용**

- 중요시설 무인 순찰 및 경계
- 자율 순찰 및 장애물 회피
- 침입 탐지 및 추적 (저조도 환경)
- 환경 이상 감지 (온도 이상, 화재/연기)
- 직관적 관제 및 자동 보고

**정량적 목표**

- 멀티모달 융합 데이터 획득 속도: 20Hz 이상
- 데이터 동기화 오차: 10ms 이내
- 3D 렌더링 품질 (PSNR): 27dB 이상
- 이상 상황 탐지 보고 성공률: 95% 이상
- 탐지-보고 평균 소요시간: 10초 이내

---

### 📋 제안/기획 중인 프로젝트

#### 1. 무인 리테일 시스템 (AI 챔피언 대회)

**기술명**: 공간지능 플랫폼 기반 무인 리테일 운영 시스템

**핵심 개념**

- **멀티모달 센서 기반 지능형 상호작용 디바이스**
- LiDAR + RGB/열화상 카메라를 매장 입구/천장에 설치
- 고객과 직접 상호작용하며 메뉴 제안, 주문 접수, 위치 추적

**주요 기능**

1. **사람 인지 및 감성적 응대**

   - LLM 기반 자연스러운 대화
   - 메뉴 추천 및 주문 접수

2. **3차원 공간 내 객체 추적**

   - 실시간 3D 맵 생성 및 업데이트
   - 고객 및 사물 위치 정밀 추적

3. **주문 매칭 및 서빙 알림**

   - 좌석-주문 자동 매칭
   - 서빙 로봇 연동

4. **매장 환경 관리 및 위험 예측**
   - 이상 상황 자동 감지 (분실물, 오염 등)
   - 관리자 실시간 알림

**차별점**

- **멀티모달 센서 융합**: 동적 환경, 조도 변화, 소음 속에서도 정확한 인지
- **LLM 기반 감성형 AI**: 언어적 + 비언어적 맥락 종합 이해
- **확장 가능한 모듈형 설계**: 고정형 → 이동형 로봇으로 확장 가능

**기대 효과**

- 24시간 무인 운영을 통한 인건비 절감
- 데이터 기반 고객 분석으로 운영 효율성 향상
- 사용자 친화적 인터페이스로 디지털 격차 해소

#### 2. 로봇 프로젝트 (기획 중)

멀티모달 센서 탑재 로봇 관련 차기 과제를 기획 중입니다.

---

## 💪 기술 역량

### 1. 멀티모달 센서 융합

- **센서 통합**: LiDAR + RGB/열화상 카메라 + IMU
- **캘리브레이션**: 내부/외부 파라미터 정밀 캘리브레이션
- **데이터 동기화**: 시점 동기화 및 타임스탬프 정합
- **융합 알고리즘**: 이종 센서 데이터 실시간 융합 및 보정

### 2. AI/ML

- **LLM 기반 시스템**: 자연어 이해, 상황 판단, 자율 행동 생성
- **컴퓨터 비전**: YOLOv8, SAM2, MediaPipe 등 최신 모델 활용
- **딥러닝**: PyTorch, TensorRT 기반 모델 최적화
- **에이전트 시스템**: 멀티 에이전트 아키텍처, Function Calling

### 3. 3D 재구성 및 공간 이해

- **SLAM**: LiDAR/IMU 기반 실시간 3D 지도 생성
- **Gaussian Splatting**: 사실적 3D 렌더링
- **NeRF**: Neural Radiance Fields
- **Semantic Mapping**: 공간 의미 이해 및 맥락 추론
- **Real2Sim**: 실제 환경 → 시뮬레이션 자동 변환

### 4. 로보틱스 & 플랫폼

- **ROS2**: 로봇 운영 체제 기반 시스템 통합
- **자율주행**: 경로 계획, 장애물 회피, SLAM
- **객체 추적**: Kalman Filter, Hungarian Algorithm
- **플랫폼**: NVIDIA Jetson Thor, Isaac Sim/ROS, Omniverse

### 5. 소프트웨어 개발

- **언어**: Python, C++
- **프레임워크**: FastAPI, Streamlit, Flask
- **데이터베이스**: PostgreSQL, Redis
- **배포**: Docker, 클라우드 컴퓨팅

---

## 🌐 대외 활동

### GTC 2026 포스터 제출

**제목**: Spatial Intelligence Architecture for Physical AI: Generation, Understanding, and Reasoning of Spatial Information

**행사**: NVIDIA GTC 2026 (글로벌 AI 컨퍼런스)

**내용**

- 공간지능의 3단계 아키텍처 제안
  1. **Reconstruction (재구성)**: 고정밀 3D 재구성
  2. **Understanding (이해)**: 의미적 공간 이해
  3. **Reasoning (추론)**: 자율적 의사결정

**핵심 메시지**

> "If Physical AI focuses on 'moving like humans',
> Spatial Intelligence focuses on 'seeing, thinking, and deciding like humans'"

**기대 효과**

- Physical AI의 진정한 자율성 실현
- 안전하고 확장 가능한 AI 학습 (시뮬레이션)
- 실제 환경에서의 자율 운영

---

## 🎯 미래 계획

### 단기 목표 (2025-2026)

1. **멀티모달 센서 플랫폼 완성**

   - 센서 융합 알고리즘 고도화
   - Real2Sim 파이프라인 구축
   - Gaussian Splatting 실시간 최적화

2. **정부 과제 성공적 완수**

   - 무인 순찰 실증 검증
   - 기술성숙도 TRL 8단계 달성

3. **무인 리테일 시스템 구현**
   - AI 챔피언 대회 참가
   - 프로토타입 제작 및 시연

### 중기 목표 (2027-2028)

1. **공간지능 플랫폼 상용화**

   - 범용 호환 인터페이스 제공
   - 다양한 로봇 플랫폼 연동 (4족, 2족, AMR 등)
   - Plug-and-Play 방식 지원

2. **확장 분야 개척**

   - 리테일: 무인 매장, 스마트 스토어
   - 헬스케어: 고령자 케어, 병원 안내
   - 보안: 무인 순찰, 침입 탐지
   - 산업: 작업 로봇, 안전 관리

3. **특허 및 논문 성과**
   - 핵심 기술 특허 출원
   - AI/로보틱스 분야 국제 학술지 게재

### 장기 비전

**"멀티모달 센서 기반 공간지능 플랫폼의 글로벌 리더"**

- Physical AI 생태계의 핵심 인터페이스 제공자
- 다양한 산업군으로 기술 확산
- 스마트 시티, 스마트홈, 자율주행 등 차세대 인프라 기반 기술 확립
- 국내 기술 수준을 세계 최고 수준으로 끌어올림

---

> **"Spatial AI로 Physical AI를 완성한다"**
>
> IVC는 멀티모달 센서 융합과 AI 기술을 통해
> 공간을 이해하고, 판단하고, 행동하는
> 차세대 공간지능 플랫폼을 만들어갑니다.
