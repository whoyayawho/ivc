## 1. 요약

### 아이디어 요약

**IVC (Innovation Vision Center)**는 물리지능(Physical AI) 시대를 대비한 **공간지능(Spatial AI) 플랫폼**을 개발함.

**SPADI (Spatial-Physical Agentic Device Interface)**를 통해 3D 비전 센서 기술과 AI를 결합하여, 공간 정보를 의미있게 만들고 물리지능 시스템에 연결하는 핵심 인터페이스를 제공함.

**Physical AI가 "사람처럼 움직이는 것"에 집중한다면, Spatial AI는 "사람처럼 보고, 생각하고, 판단하는 것"에 집중함.**

라이다를 직접 설계, 제조하는 하드웨어 역량을 기반으로, 3D 공간 인지 → AI 기반 이해 → 물리 행동 명령의 완전한 파이프라인을 **Plug-and-Play 방식**으로 제공함.

### 핵심 가치 제안

**"Spatial AI로 Physical AI를 완성시킨다"**

- **공간지능 플랫폼**: 3D 공간 인지 → 의미 이해 → 행동 명령 생성의 완전한 파이프라인
  - **Real2Sim 기술**: 실제 환경을 시뮬레이션으로 변환
  - **Gaussian Splatting**: 사실적 3D 렌더링 및 공간 재구성
  - **Semantic Mapping**: 공간의 의미적 이해 및 맥락 파악
- **자체 라이다 기술**: 고정형 라이다 설계/제조 역량 기반, 검증된 하드웨어 품질
- **NVIDIA 생태계**: Jetson Thor 기반, Physical AI에 최적화, 800 TOPS AI 성능
- **Spatial-Physical 인터페이스**: 공간 정보를 물리지능 시스템이 이해할 수 있는 형태로 변환
- **범용 호환성**: 모든 로봇 플랫폼 (4족, 2족, 바퀴형, 고정 인프라) 호환
- **AI 에이전트**: LLM 기반 상황 판단 및 자율 행동 생성

### 기술적 기대 효과

- 세계 최초 LLM 기반 범용 로봇 헤드 시스템
- NVIDIA Jetson Thor 기반 Physical AI 플랫폼 구축
- Spatial AI 기술을 통한 로봇의 진정한 자율성 실현

---

## 2. 기술 개요

### 2.1 핵심 철학

- **"Spatial AI로 Physical AI를 완성한다"**
  - 공간을 이해하는 지능을 통해 로봇의 물리적 행동을 가능케 함
  - 3D 비전 센서 기술과 AI를 결합한 공간지능 플랫폼

### 2.2 핵심 가치

1. **기술 우선**: 자체 라이다 설계/제조 역량 기반의 하드웨어 전문성
2. **공간지능**: Physical AI와 차별화된 Spatial AI 기술 리더십
3. **개방성**: 모든 로봇 플랫폼과 호환되는 범용 인터페이스
4. **지속 혁신**: AI 모델 지속 업데이트 및 성능 향상

### 2.3 기술 개발 로드맵

**배경:**
- **모기업**: 고정형 라이다 개발 전문 기업 (3D 비전 센서 설계/제조 역량 보유)
- **IVC (Innovation Vision Center) 출범**: **2025년 초** 신규 조직으로 출범
- **핵심 통찰**: "라이다가 공간을 스캔하는 것을 넘어, 공간을 *이해*하게 만들어야 한다"
- **차별화 전략**: 라이다 제조 역량을 활용한 하드웨어+소프트웨어 통합 솔루션

**기술 개발 3단계:**

**1단계 (2025): 멀티모달 센서 모듈**
- **기술 목표**: 멀티모달 센서 융합 데이터 출력
- **핵심 구성**: 라이다 + RGB/열화상 카메라 + IMU 통합 센서
- **기술 개발**:
  - NVIDIA Jetson Thor 플랫폼 통합
  - 센서 융합 알고리즘 개발
  - ROS2 기반 데이터 출력 파이프라인

**2단계 (2026): Plug-and-Play 자율주행 모듈**
- **기술 목표**: 다양한 로봇 플랫폼에 즉시 장착 가능한 자율주행 솔루션
- **핵심 기능**:
  - 4족, 2족, 바퀴형 로봇 범용 호환 시스템
  - LLM 기반 자연어 명령 처리
  - 게임형 설정 인터페이스
  - Isaac ROS 자율주행 스택 통합
  - 클라우드 연동 및 OTA 업데이트 시스템
- **기술 개발**:
  - 자율주행 모듈 v2.0 개발
  - 멀티플랫폼 호환성 검증

**3단계 (2027-2028): 완전한 공간지능 플랫폼**
- **기술 목표**: Spatial AI 기반 고도화된 공간 이해 및 의사결정
- **핵심 기능**:
  - **Real2Sim 기술**: 실제 환경을 고정밀 시뮬레이션 환경으로 변환
  - **Gaussian Splatting**: 실시간 사실적 3D 렌더링 및 공간 재구성
  - **Semantic Mapping**: 공간 의미 이해 (주방, 침실, 위험 구역 자동 인식)
  - 상황 인지 및 자율 판단 시스템
  - AI 에이전트 시스템
  - NVIDIA Omniverse 완전 통합
- **기술 개발**:
  - Real2Sim 파이프라인 구축 및 자동화
  - Gaussian Splatting 실시간 최적화
  - Semantic Mapping 고도화
  - v3.0 플랫폼 개발

---

## 3. 제품 및 기술

### 3.1 제품 개요

- **제품명:** **SPADI** (Spatial-Physical Agentic Device Interface)
- **상세 설명:**
  - **공간지능(Spatial AI) 플랫폼**: 3D 비전 센서로 공간을 인지하고, AI로 의미를 이해하며, 물리지능 시스템에 행동 명령을 전달하는 완전한 파이프라인
    - **Real2Sim**: 실제 환경을 고정밀 시뮬레이션으로 변환하여 로봇 개발 효율 극대화
    - **사실적 3D 렌더링**: Gaussian Splatting 기술로 실시간 사실적 공간 재구성
    - **Semantic Mapping**: 공간의 의미적 맥락 이해 및 지능적 행동 생성
  - **Spatial-Physical 인터페이스**: 공간 정보를 Physical AI가 이해할 수 있는 형태로 변환하는 핵심 인터페이스
  - **자체 라이다 기반**: 모기업의 고정형 라이다 설계/제조 기술을 활용한 검증된 하드웨어
  - **Plug-and-Play**: 다양한 로봇 플랫폼에 즉시 장착 가능한 통합 모듈
- **주요 기능/특징:**
  1. **3D 공간 인지**: 자체 개발 라이다 + RGB/열화상 카메라로 정밀한 3D 공간 스캔 및 객체 인식
  2. **Real2Sim 파이프라인**: 실제 환경을 NVIDIA Omniverse 기반 고정밀 시뮬레이션으로 변환하여 로봇 학습 및 테스트 환경 제공
  3. **Gaussian Splatting 기반 3D 렌더링**: 실시간 사실적 3D 공간 재구성 및 모델링
  4. **Semantic Mapping**: LLM 기반 공간 의미 이해 (예: "주방", "장애물", "통로", "목표 지점")
  5. **Physical AI 연동**: 공간 정보를 로봇 제어 명령으로 변환 (navigation, manipulation 등)
  6. **에이전트 시스템**: 상황 판단 및 자율 행동 계획 생성
  7. **범용 호환성**: 4족, 2족, AMR, 매니퓰레이터, 고정 인프라 등 모든 플랫폼 지원
  8. **실시간 처리**: 엣지 AI 프로세싱으로 저지연 응답 (<100ms)
- **핵심 기술 스택:**
  1. **컴퓨팅**: NVIDIA Jetson Thor (800 TOPS AI 성능, Transformer Engine, CUDA/TensorRT/Isaac SDK)
  2. **센서**: 라이다 (모회사 자체 개발), RGB 카메라 (기본), 열화상 카메라 (Pro), IMU, 음성 (옵션)
  3. **AI**: Google Gemini (메인 LLM), OpenAI GPT/Anthropic Claude (선택 가능), 자체 공간 AI 모델
  4. **소프트웨어**:
     - **기본 프레임워크**: ROS2, NVIDIA Isaac Sim/ROS, PyTorch, TensorRT
     - **3D 재구성**: Gaussian Splatting, NeRF (Neural Radiance Fields)
     - **공간 이해**: Semantic Mapping, Scene Understanding, Real2Sim 파이프라인
     - **시뮬레이션**: NVIDIA Omniverse, Isaac Sim

### 3.2 핵심 기술적 이점

**해결하는 기술적 문제:**

- 로봇 개발사들의 센서 통합 및 AI 시스템 중복 투자
- 멀티모달 센서 데이터 융합의 복잡성

**제공하는 기술 솔루션:**

- **All-in-One 통합 솔루션**: 센서 하드웨어 + AI 소프트웨어 + 통신 인터페이스 완전 패키징
- **Plug-and-Play**: 로봇 몸체에 장착만 하면 바로 작동
- **지속적인 AI 업데이트**: 클라우드 기반 모델 업데이트로 성능 지속 향상 (OTA)

**기술적 장점:**

1. **개발 효율성**: 센서 융합 및 AI 통합 자동화
2. **최신 기술 적용**: 최신 LLM 및 멀티모달 AI 기술 즉시 적용
3. **범용성**: 다양한 로봇 플랫폼에 동일한 시스템 재사용 가능

### 3.3 개발 현황

**현재 개발 단계:** 프로토타입 개발 단계

**완료된 개발:**

- 기본 센서 통합 모듈 설계
- LLM 기반 의사결정 프레임워크 설계
- Isaac Sim 시뮬레이션에서 샘플 로봇 플랫폼(예: 4족 로봇) 연동 테스트
- 기본 환경 인지 및 객체 인식 기능

**향후 필요 개발:**

- **Real2Sim 파이프라인**: 실제 환경 스캔 → 시뮬레이션 변환 자동화
- **Gaussian Splatting 구현**: 실시간 3D 렌더링 및 공간 재구성 시스템
- **Semantic Mapping 고도화**: 공간 의미 이해 및 맥락 추론 AI 모델
- 실제 로봇 플랫폼과의 물리적 연동 및 현장 테스트
- 다양한 로봇 타입(4족, 2족, 바퀴형)과의 호환성 검증

**R&D 투자 계획:**

- Year 1: AI 모델 개발 및 센서 융합 알고리즘
  - 기본 센서 융합 및 데이터 처리 파이프라인
  - Semantic Mapping 기초 모델 개발
- Year 2: 플랫폼 확장 및 최적화
  - Real2Sim 파이프라인 구축
  - Gaussian Splatting 기반 3D 렌더링 시스템
  - Semantic Mapping 고도화
- Year 3: 차세대 센서 및 AI 기술 통합 연구
  - Real2Sim 자동화 및 대규모 환경 처리
  - 사실적 3D 모델링 실시간 성능 최적화
  - 공간 이해 AI의 맥락 추론 및 예측 기능 고도화

### 3.4 지적재산권

**특허 (출원 예정):**

1. 멀티모달 센서 데이터 융합 방법 및 시스템
2. Real2Sim 기반 환경 변환 및 시뮬레이션 자동화 방법
3. Gaussian Splatting을 활용한 실시간 3D 공간 재구성 시스템
4. Semantic Mapping 기반 공간 의미 이해 및 행동 생성 알고리즘
5. 범용 로봇 인터페이스 표준 프로토콜
6. LLM 기반 로봇 행동 생성 알고리즘
7. Plug-and-Play 로봇 헤드 모듈 설계

**전략:**

- 핵심 알고리즘은 독점, 인터페이스는 표준화
- ROS2 기반 개발로 커뮤니티 생태계 활용

---

## 4. NVIDIA 생태계 통합

### 4.1 왜 NVIDIA Jetson Thor인가?

**기술적 우위:**

- **Physical AI 특화**: 800 TOPS AI 성능 (기존 대비 5배), Transformer Engine (LLM 최적화)
- **완벽한 소프트웨어 생태계**: JetPack SDK, Isaac ROS/Sim, TensorRT, CUDA
- **미래 확장성**: Omniverse 통합, 차세대 Jetson 업그레이드, 글로벌 개발자 커뮤니티

### 4.2 기술적 이점

- AI 모델 최적화 및 고성능 추론 지원
- Isaac SDK를 통한 개발 효율성 향상
- CUDA 및 TensorRT를 통한 실시간 처리 성능
- Omniverse 통합을 통한 시뮬레이션 및 Real2Sim 구현

