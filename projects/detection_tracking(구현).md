## π“‹ λ©μ°¨

- [κ°μ”](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [μ£Όμ” κΈ°λ¥](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [μ‹μ¤ν… μ•„ν‚¤ν…μ²](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [μ„¤μΉ λ°©λ²•](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [μ‚¬μ© λ°©λ²•](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [ROS2 μΈν„°νμ΄μ¤](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [νλΌλ―Έν„° μ„¤μ •](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)
- [κΈ°μ  μ¤νƒ](https://www.notion.so/3D-Human-Detection-and-Tracking-System-264488fcddd08080a9bcf9c127860a83?pvs=21)

## κ°μ”

λ³Έ ν¨ν‚¤μ§€λ” ROS2 ν™κ²½μ—μ„ μΉ΄λ©”λΌμ™€ λΌμ΄λ‹¤ μ„Όμ„ λ°μ΄ν„°λ¥Ό μµν•©ν•μ—¬ μ‹¤μ‹κ°„μΌλ΅ μ‚¬λμ„ κ°μ§€, μ¶”μ ν•κ³  μ μ¤μ²λ¥Ό μΈμ‹ν•λ” ν†µν•© μ‹μ¤ν…μ…λ‹λ‹¤. YOLOv8, SAM2, MediaPipe λ“± μµμ‹  λ”¥λ¬λ‹ λ¨λΈμ„ ν™μ©ν•λ©°, Kalman Filter κΈ°λ° λ‹¤μ¤‘ κ°μ²΄ μ¶”μ μ„ ν†µν•΄ μ•μ •μ μΈ 3D κ¶¤μ  μ¶”μ μ„ μ κ³µν•©λ‹λ‹¤.

## μ£Όμ” κΈ°λ¥

### 1. π― κ°μ²΄ κ°μ§€ λ° μ„Έκ·Έλ©ν…μ΄μ…

- **YOLOv8**: μ‹¤μ‹κ°„ κ°μ²΄ κ°μ§€ (person ν΄λμ¤)
- **SAM2 (Segment Anything Model 2)**: μ •λ°€ν• μΈμ¤ν„΄μ¤ μ„Έκ·Έλ©ν…μ΄μ…
- λ°”μ΄λ”© λ°•μ¤ λ° λ§μ¤ν¬ κΈ°λ° 3D ν¬μΈνΈ μ¶”μ¶

### 2. πƒ μ¤μΌλ ν†¤ λ° μ μ¤μ² μΈμ‹

- **MediaPipe Pose**: 33κ° λλ“λ§ν¬ κΈ°λ° μ¤μΌλ ν†¤ κ°μ§€
- μ† λ“¤κΈ° μ μ¤μ² μΈμ‹ (μ–‘μ†/ν•μ† κµ¬λ¶„)
- μ‹¤μ‹κ°„ μ¤μΌλ ν†¤ μ‹κ°ν™”

### 3. π“ λ‹¤μ¤‘ κ°μ²΄ μ¶”μ  (MOT)

- **Kalman Filter**: 6μ°¨μ› μƒνƒ κ³µκ°„ (μ„μΉ + μ†λ„) μμΈ΅
- **Hungarian Algorithm**: μµμ  λ°μ΄ν„° μ—°κ΄€
- κ°μΈλ³„ κ³ μ  ID λ¶€μ—¬ λ° μƒ‰μƒ κµ¬λ¶„
- 3D κ¶¤μ  κΈ°λ΅ λ° μ‹κ°ν™”

### 4. π 3D ν¬μΈνΈ ν΄λΌμ°λ“ μ²λ¦¬

- μΉ΄λ©”λΌ-λΌμ΄λ‹¤ μΊλ¦¬λΈλ μ΄μ… κΈ°λ° μ„Όμ„ μµν•©
- DBSCAN ν΄λ¬μ¤ν„°λ§μ„ ν†µν• λ…Έμ΄μ¦ μ κ±°
- Statistical Outlier Removal (SOR) ν•„ν„°λ§
- μƒ‰μƒ λ§¤ν•‘λ 3D ν¬μΈνΈ ν΄λΌμ°λ“ μƒμ„±

### 5. π“ RViz2 3D μ‹κ°ν™”

- 3D λ°”μ΄λ”© λ°•μ¤ λ§μ»¤
- μ‹¤μ‹κ°„ κ¶¤μ  λΌμΈ ν‘μ‹
- μ μ¤μ² μƒνƒ ν…μ¤νΈ ν‘μ‹
- μ¶”μ  ID ν‘μ‹

## μ‹μ¤ν… μ•„ν‚¤ν…μ²

```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                     DetectHumanNode (ROS2)                   β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚                                                               β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”      β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                     β”‚
β”‚  β”‚ Image Input  β”‚      β”‚PointCloud    β”‚                     β”‚
β”‚  β”‚ (Compressed) β”‚      β”‚   Input      β”‚                     β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”      β””β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”                     β”‚
β”‚         β”‚                      β”‚                             β”‚
β”‚         β–Ό                      β–Ό                             β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                    β”‚
β”‚  β”‚    Synchronization Buffer            β”‚                    β”‚
β”‚  β”‚    (25ms tolerance)                  β”‚                    β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                    β”‚
β”‚                 β–Ό                                            β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”        β”‚
β”‚  β”‚            Detection Pipeline                     β”‚        β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤       β”‚
β”‚  β”‚                                                   β”‚       β”‚
β”‚  β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”      β”‚       β”‚
β”‚  β”‚  β”‚  YOLOv8  β”‚β†’ β”‚   SAM2   β”‚β†’ β”‚MediaPipe β”‚      β”‚       β”‚
β”‚  β”‚  β”‚Detection β”‚  β”‚Segmentationβ”‚ β”‚  Pose    β”‚      β”‚       β”‚
β”‚  β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”      β”‚       β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”        β”‚
β”‚                        β–Ό                                    β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”       β”‚
β”‚  β”‚          Multi-Person Tracker                    β”‚       β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤      β”‚
β”‚  β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”      β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”         β”‚      β”‚
β”‚  β”‚  β”‚Kalman Filter β”‚  β†β†’  β”‚  Hungarian   β”‚         β”‚      β”‚
β”‚  β”‚  β”‚  (per ID)    β”‚      β”‚  Algorithm   β”‚         β”‚      β”‚
β”‚  β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”      β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”         β”‚      β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”       β”‚
β”‚                        β–Ό                                   β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β”‚
β”‚  β”‚              Output Publishers                     β”‚    β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤   β”‚
β”‚  β”‚ β€Ά /human_detections (Detection2DArray)             β”‚   β”‚
β”‚  β”‚ β€Ά /human_segmentation_image (Image)                β”‚   β”‚
β”‚  β”‚ β€Ά /human_pointcloud (PointCloud2)                  β”‚   β”‚
β”‚  β”‚ β€Ά /masked_pointcloud (PointCloud2)                 β”‚   β”‚
β”‚  β”‚ β€Ά /human_bounding_boxes (MarkerArray)              β”‚   β”‚
β”‚  β”‚ β€Ά /human_trajectories (MarkerArray)                β”‚   β”‚
β”‚  β”‚ β€Ά /yolo_detection_image (Image)                    β”‚   β”‚
β”‚  β”‚ β€Ά /projected_image (Image)                         β”‚   β”‚
β”‚  β”‚ β€Ά /colored_pointcloud (PointCloud2)                β”‚   β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”   β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”

```

### ν΄λμ¤ κµ¬μ΅°

### PersonTracker

- κ°λ³„ μ‚¬λ μ¶”μ μ„ μ„ν• Kalman Filter κΈ°λ° νΈλμ»¤
- 6μ°¨μ› μƒνƒ λ²΅ν„°: [x, y, z, vx, vy, vz]
- κ¶¤μ  νμ¤ν† λ¦¬ κ΄€λ¦¬ (μµλ€ 100ν¬μΈνΈ)

### MultiPersonTracker

- λ‹¤μ¤‘ PersonTracker κ΄€λ¦¬
- Hungarian Algorithmμ„ ν†µν• detection-to-tracker λ§¤μΉ­
- νΈλμ»¤ μƒμ„±/μ‚­μ  κ΄€λ¦¬

### DetectHumanNode

- λ©”μΈ ROS2 λ…Έλ“
- μ„Όμ„ λ°μ΄ν„° λ™κΈ°ν™”
- AI λ¨λΈ ν†µν•© λ° μ‹¤ν–‰
- κ²°κ³Ό νΌλΈ”λ¦¬μ‹±

## ν”„λ΅μ νΈ κµ¬μ΅°

```
detect_human/
β”β”€β”€ config/
β”‚   β””β”€β”€ detection_params.yaml      # κ°μ§€ λ° μ¶”μ  νλΌλ―Έν„° μ„¤μ •
β”β”€β”€ data/
β”‚   β””β”€β”€ calibration_params.json    # μΉ΄λ©”λΌ-LiDAR μΊλ¦¬λΈλ μ΄μ… νλΌλ―Έν„°
β”β”€β”€ detect_human/
β”‚   β”β”€β”€ __init__.py
β”‚   β”β”€β”€ detect_human_node.py       # κΈ°λ³Έ μµν•© λ…Έλ“ (κ°μ§€ λ―Έν¬ν•¨)
β”‚   β”β”€β”€ detect_human_node_with_detection.py  # AI ν†µν•© λ©”μΈ λ…Έλ“
β”‚   β””β”€β”€ sam2/                      # SAM2 λ¨λΈ λ””λ ‰ν† λ¦¬
β”β”€β”€ launch/
β”‚   β””β”€β”€ detect_human.launch.py     # RViz2 ν†µν•© λ°μΉ νμΌ
β”β”€β”€ models/                         # AI λ¨λΈ κ°€μ¤‘μΉ
β”‚   β””β”€β”€ sam2.1_hiera_base_plus.pt
β”β”€β”€ resource/
β”‚   β””β”€β”€ detect_human               # ROS2 ν¨ν‚¤μ§€ λ§μ»¤
β”β”€β”€ rviz/
β”‚   β””β”€β”€ config.rviz                # RViz2 μ‹κ°ν™” μ„¤μ •
β”β”€β”€ package.xml                    # ν¨ν‚¤μ§€ μμ΅΄μ„±
β”β”€β”€ setup.py                       # Python ν¨ν‚¤μ§€ μ„¤μ •
β””β”€β”€ setup.cfg                      # λΉλ“ μ„¤μ •

```

## μ„¤μΉ λ°©λ²•

### 1. μ‹μ¤ν… μ”κµ¬μ‚¬ν•­

- Ubuntu 22.04
- ROS2 Humble
- Python 3.10+
- CUDA 11.8+ (GPU μ‚¬μ© μ‹)

### 2. μμ΅΄μ„± ν¨ν‚¤μ§€ μ„¤μΉ

```bash
# ROS2 ν¨ν‚¤μ§€
sudo apt update
sudo apt install ros-humble-vision-msgs ros-humble-visualization-msgs

# Python ν¨ν‚¤μ§€
pip install torch torchvision ultralytics mediapipe opencv-python scipy open3d

```

### 3. SAM2 λ¨λΈ μ„¤μΉ

```bash
cd /root/ros2_ws/src/detect_human/detect_human
git clone <https://github.com/facebookresearch/segment-anything-2.git> sam2
cd sam2
pip install -e .

# λ¨λΈ κ°€μ¤‘μΉ λ‹¤μ΄λ΅λ“
cd /root/ros2_ws/src/detect_human/models
wget <https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2.1_hiera_base_plus.pt>

```

### 4. ν¨ν‚¤μ§€ λΉλ“

```bash
cd /root/ros2_ws
colcon build --packages-select detect_human
source install/setup.bash

```

## μ‚¬μ© λ°©λ²•

### 1. κΈ°λ³Έ μ‹¤ν–‰

```bash
# Launch νμΌλ΅ μ‹¤ν–‰ (RViz2 ν¬ν•¨)
ros2 launch detect_human detect_human.launch.py

# λλ” λ…Έλ“λ§ μ‹¤ν–‰
ros2 run detect_human detect_human_node_with_detection

```

### 2. νλΌλ―Έν„° μμ •ν•μ—¬ μ‹¤ν–‰

```bash
# YAML μ„¤μ • νμΌ μμ •
nano /root/ros2_ws/src/detect_human/config/detection_params.yaml

# νλΌλ―Έν„° μ¤λ²„λΌμ΄λ“
ros2 run detect_human detect_human_node_with_detection \\
  --ros-args \\
  -p enable_tracking:=true \\
  -p yolo_confidence:=0.6 \\
  -p trajectory_max_length:=50

```

### 3. μΊλ¦¬λΈλ μ΄μ… νλΌλ―Έν„° μ„¤μ •

```bash
# calibration_params.json μμ •
nano /root/ros2_ws/src/detect_human/data/calibration_params.json

```

## ROS2 μΈν„°νμ΄μ¤

### μ…λ ¥ ν† ν”½

| ν† ν”½λ…                                                   | λ©”μ‹μ§€ νƒ€μ…                   | μ„¤λ…                      |
| -------------------------------------------------------- | ----------------------------- | ------------------------- |
| `/my_camera/pylon_ros2_camera_node/image_raw/compressed` | `sensor_msgs/CompressedImage` | μ••μ¶•λ μΉ΄λ©”λΌ μ΄λ―Έμ§€      |
| `/pointcloud`                                            | `sensor_msgs/PointCloud2`     | 3D λΌμ΄λ‹¤ ν¬μΈνΈ ν΄λΌμ°λ“ |

### μ¶λ ¥ ν† ν”½

| ν† ν”½λ…                      | λ©”μ‹μ§€ νƒ€μ…                      | μ„¤λ…                                      |
| --------------------------- | -------------------------------- | ----------------------------------------- |
| `/human_detections`         | `vision_msgs/Detection2DArray`   | 2D κ°μ§€ κ²°κ³Ό λ°°μ—΄                         |
| `/human_segmentation_image` | `sensor_msgs/Image`              | μ„Έκ·Έλ©ν…μ΄μ… + μ¤μΌλ ν†¤ μ¤λ²„λ μ΄ μ΄λ―Έμ§€   |
| `/human_pointcloud`         | `sensor_msgs/PointCloud2`        | κ°μ§€λ μ‚¬λμ 3D ν¬μΈνΈ                   |
| `/masked_pointcloud`        | `sensor_msgs/PointCloud2`        | λ§μ¤ν¬ μƒ‰μƒμ΄ μ μ©λ μ „μ²΄ ν¬μΈνΈ ν΄λΌμ°λ“ |
| `/human_bounding_boxes`     | `visualization_msgs/MarkerArray` | RViz2μ© 3D λ°”μ΄λ”© λ°•μ¤                    |
| `/human_trajectories`       | `visualization_msgs/MarkerArray` | RViz2μ© κ¶¤μ  μ‹κ°ν™”                       |
| `/yolo_detection_image`     | `sensor_msgs/Image`              | YOLO κ°μ§€ κ²°κ³Ό μ΄λ―Έμ§€                     |
| `/projected_image`          | `sensor_msgs/Image`              | ν¬μΈνΈ ν΄λΌμ°λ“ ν¬μ μ΄λ―Έμ§€               |
| `/colored_pointcloud`       | `sensor_msgs/PointCloud2`        | RGB μƒ‰μƒμ΄ λ§¤ν•‘λ ν¬μΈνΈ ν΄λΌμ°λ“         |

## νλΌλ―Έν„° μ„¤μ •

### μ£Όμ” νλΌλ―Έν„°

### κ°μ§€ νλΌλ―Έν„°

- `enable_human_detection` (bool, default: true): μ‚¬λ κ°μ§€ ν™μ„±ν™”
- `yolo_model_path` (string, default: "[yolov8m.pt](http://yolov8m.pt/)"): YOLO λ¨λΈ κ²½λ΅
- `yolo_confidence` (float, default: 0.5): YOLO μ‹ λΆ°λ„ μ„κ³„κ°’
- `sam2_model_size` (string, default: "base_plus"): SAM2 λ¨λΈ ν¬κΈ°

### ν¬μ¦/μ μ¤μ² νλΌλ―Έν„°

- `enable_pose_detection` (bool, default: true): ν¬μ¦ κ°μ§€ ν™μ„±ν™”
- `enable_gesture_detection` (bool, default: true): μ μ¤μ² μΈμ‹ ν™μ„±ν™”
- `hands_up_y_offset` (int, default: 20): μ† λ“¤κΈ° νλ‹¨ ν”½μ…€ μ¤ν”„μ…‹

### μ¶”μ  νλΌλ―Έν„°

- `enable_tracking` (bool, default: true): λ‹¤μ¤‘ κ°μ²΄ μ¶”μ  ν™μ„±ν™”
- `max_tracking_distance` (float, default: 1.0): μµλ€ λ§¤μΉ­ κ±°λ¦¬ (m)
- `max_frames_to_skip` (int, default: 30): νΈλμ»¤ μ κ±° μ „ μµλ€ ν”„λ μ„
- `trajectory_max_length` (int, default: 30): κ¶¤μ  μµλ€ κΈΈμ΄

### ν΄λ¬μ¤ν„°λ§ νλΌλ―Έν„°

- `enable_clustering` (bool, default: true): DBSCAN ν΄λ¬μ¤ν„°λ§ ν™μ„±ν™”
- `cluster_eps` (float, default: 0.01): ν΄λ¬μ¤ν„° μµλ€ κ±°λ¦¬ (m)
- `cluster_min_points` (int, default: 10): ν΄λ¬μ¤ν„° μµμ† ν¬μΈνΈ μ

### μ„±λ¥ νλΌλ―Έν„°

- `skip_frames` (int, default: 0): ν”„λ μ„ μ¤ν‚µ μ
- `max_detections` (int, default: 10): μµλ€ κ°μ§€ μΈμ›
- `use_gpu` (bool, default: true): GPU κ°€μ† μ‚¬μ©

### μ„¤μ • νμΌ μμ‹

```yaml
detect_human_node:
  ros__parameters:
    # κ°μ§€ μ„¤μ •
    enable_human_detection: true
    yolo_model_path: "yolov8m.pt" # n, s, m, l, x μ‚¬μ© κ°€λ¥
    yolo_confidence: 0.5
    sam2_model_size: "base_plus" # tiny, small, base_plus, large

    # μ¶”μ  μ„¤μ •
    enable_tracking: true
    trajectory_max_length: 50
    max_frames_to_skip: 30

    # ν¬μ¦/μ μ¤μ²
    enable_pose_detection: true
    enable_gesture_detection: true

    # μ„±λ¥ μµμ ν™”
    use_gpu: true
    skip_frames: 0
```

## μΊλ¦¬λΈλ μ΄μ… μ„¤μ •

μΊλ¦¬λΈλ μ΄μ… νμΌ (`data/calibration_params.json`) λ‚΄μ©:

```json
{
  "camera_matrix": {
    "fx": 1147.424,
    "fy": 1147.424,
    "cx": 960.0,
    "cy": 600.0,
    "skew": 0.0
  },
  "dist_coeffs": {
    "k1": -0.098,
    "k2": -0.078,
    "k3": 0.0,
    "p1": -0.005,
    "p2": 0.002
  },
  "quaternions": {
    "x": 0.514,
    "y": -0.506,
    "z": 0.496,
    "w": 0.484
  },
  "tvecs": {
    "tx": 0.116,
    "ty": -0.014,
    "tz": -0.02
  }
}
```

## κΈ°μ  μ¤νƒ

### AI/ML ν”„λ μ„μ›ν¬

- **YOLOv8**: Ultralyticsμ μµμ‹  κ°μ²΄ κ°μ§€ λ¨λΈ
- **SAM2**: Metaμ Segment Anything Model 2.1
- **MediaPipe**: Googleμ ν¬μ¦ κ°μ§€ μ†”λ£¨μ…
- **PyTorch**: λ”¥λ¬λ‹ ν”„λ μ„μ›ν¬

### μ»΄ν“¨ν„° λΉ„μ „

- **OpenCV**: μ΄λ―Έμ§€ μ²λ¦¬ λ° μ‹κ°ν™”
- **Open3D**: ν¬μΈνΈ ν΄λΌμ°λ“ ν•„ν„°λ§ (μµμ…)

### μ¶”μ  μ•κ³ λ¦¬μ¦

- **Kalman Filter**: μƒνƒ μμΈ΅ λ° μ—…λ°μ΄νΈ
- **Hungarian Algorithm**: μµμ  ν• λ‹Ή λ¬Έμ  ν•΄κ²°
- **DBSCAN**: λ°€λ„ κΈ°λ° ν΄λ¬μ¤ν„°λ§

### ROS2 ν¨ν‚¤μ§€

- `vision_msgs`: κ°μ§€ κ²°κ³Ό λ©”μ‹μ§€
- `visualization_msgs`: RViz2 λ§μ»¤
- `cv_bridge`: OpenCV-ROS λΈλ¦¬μ§€
