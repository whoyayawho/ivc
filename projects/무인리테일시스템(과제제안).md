다음은 PDF 파일의 내용을 마크다운으로 변환한 것입니다.

-----

[붙임2] 구현제안서 양식(v1.0)

# 인공지능 챔피언 대회 구현제안서

2025. 7.  21\.

| | |
| :--- | :--- |
| **기술명** | 공간지능 플랫폼 기반 무인 리테일 운영 시스템 |
| **팀명** | 스패디(SPADI) |
| **참여인원** | 5명 |

-----

[붙임2] 구현제안서 양식(v1.0)

## 1\. 일반 사항

| | |
| :--- | :--- |
| **1.1 기술명** | 공간지능 플랫폼 기반 무인 리테일 운영 시스템 |
| **1.2 하드웨어 포함 여부** | **예(Yes)** 아니오(No) |
| **1.2.1 하드웨어 설명 (필요시)** | [멀티모달 기반 지능형 상호작용 디바이스]<br> \* 열화상/RGB 카메라, LiDAR, 디스플레이, 마이크, 스피커 등으로 구성<br> \* 매장 입구 또는 주요 지점에 설치되어 고객과 직접 상호작용<br><br>[3D 고정형 라이다]<br> \* 매장 천장과 같이 넓은 시야각을 확보할 수 있는 여러 위치에 설치<br> \* 개별 센서의 한계를 넘어 매장 전체의 공간 정보를 3차원으로 정밀하게 스캔<br> \* 고객의 이동 경로와 사물의 배치를 실시간으로 파악<br><br>[중앙 제어기]<br> \* 매장에 설치된 모든 센서로부터 수집되는 대용량의 이종 데이터를 실시간으로 처리<br> \* 복잡한 연산을 위한 고성능 컴퓨팅 자원을 활용<br> \* 시스템 전반의 운영 시나리오를 관장하고, 데이터 보안 및 시스템 상태 모니터링, 각 장치에 필요한 명령 전달 등 중앙 허브 역할을 수행 |
| **1.3 활용 분야** | 범용, 리테일, 스마트홈, 산업, 공공 |
| **1.4 기술성숙도** | 실험 단계 (TRL1\~4) |
| **1.5 도입 수준** | 도입전 |
| **1.6 유사 기술** | \* 스마트 스피커의 형태로 음성 인식 및 명령 수행 기능을 제공 (명령-응답 구조)<br> \* 홈 IoT 연동된 기기를 통해 스마트홈 환경의 다양한 작업 수행 가능<br> \* 85% 이상이 Amazon Alexa, Google Assistant와 같은 외산 브랜드에 의존<br> \* 국내에서는 삼성전자, LG전자, 한컴로보틱스 등이 스마트홈 AI 기기 또는 단일 목적의 케어 로봇을 개발<br> \* 대부분 카메라나 마이크 기반의 단일 센서로 활용 방법과 기능에 한계가 존재 |
| **1.7 차별점** | [멀티모달 센서 융합을 통한 종합적이고 정확한 공간 맥락 파악]<br> \* 단순 카메라나 마이크에 의존하는 기존 시스템과 달리, LiDAR, 열화상, RGB 카메라 등 다중 센서 데이터를 통합<br> \* 동적 환경 변화나 조도 변화, 소음 등 외부 환경의 제약 속에서도 고객과 공간을 종합적이고 정확하게 인지<br> \* 실시간 3D 맵 생성, 환경 내 사람 및 객체 인지 및 정밀 추적 등의 기능 제공<br><br>[LLM(대규모 언어 모델) 기반 감성형 AI 상호작용]<br> \* 사용자의 언어적 명령뿐만 아니라, 센서로 파악된 비언어적 맥락(표정, 움직임, 주변 상황)까지 이해하여 깊이 있는 상호작용을 구현<br> \* 단순 정보 전달을 넘어 고객의 잠재적 의도를 파악하고 감성적 유대감을 형성하는 차별화된 고객 경험을 제공<br> \* 메뉴 제안, 주문 접수, 결제 연동 등 무인 리테일 환경에 특화된 대화 로직 구현<br><br>[확장 가능한 모듈형 플랫폼 설계]<br> \* 초기 고정형 디바이스에서 향후 2족/4족 보행 로봇 등 다양한 시스템과 결합할 수 있는 유연한 모듈형 아키텍처로 설계<br> \* 지속적인 기능 확장이 가능한 미래 지향적 플랫폼 설계<br> \* 홈 서비스, 헬스케어, 서비스 로봇 등 다양한 환경으로 스며들 수 있도록 확장 가능 |

## 2\. 기술 명세

| | |
| :--- | :--- |
| **2.1 기술 목적** | \* 공간지능(Spatial Al)을 기반으로 단순히 명령에 반응하는 것을 넘어 스스로 상황을 인지하고 사용자와 감성적으로 교감하는 플랫폼 개발<br> \* 자율적으로 대응하는 차세대 지능형 상호작용 디바이스 개발<br> \* 무인 리테일 환경에 적용하여 24시간 운영에 따른 인건비 부담을 줄이고, 데이터 기반의 고객 분석을 통해 운영 효율성과 안전성을 극대화 |

\-1-

-----

[붙임2] 구현제안서 양식(v1.0)

| | |
| :--- | :--- |
| **2.2 기술 구조** | [멀티모달 센서 모듈]<br> \* 이종 센서들로부터 원시 데이터를 수집<br> \* 각 데이터의 노이즈를 제거하며 시점 동기화<br><br>[공간 파악 모듈]<br> \* 전처리 데이터를 바탕으로 실시간 3D 맵을 생성<br> \* 시맨틱 분할(Semantic Segmentation) 기술로 공간 내 객체(고객, 테이블, 상품)를 인지하고 추적<br> \* 공간 내 정보는 '공간적 맥락'으로서 하위 모듈에 전달<br><br>[LLM 기반 상호작용 모듈]<br> \* 공간 파악 모듈로부터 전달받은 맥락 정보와 사용자의 음성/텍스트 입력을 통합<br> \* 대규모 언어 모델(LLM)이 사용자의 의도를 깊이 있게 파악하고 감성적인 대화를 생성<br><br>[행동/응답 모듈]<br> \* LLM의 판단을 바탕으로 구체적인 행동을 결정 (예를 들어, '서빙 로봇에 A테이블로 이동하라는 명령 전송', '관리자에게 재고 부족 알림 발송' 등 자율적인 임무를 지시)<br><br>[출력/인터페이스 모듈]<br> \* 결정된 행동을 디스플레이, 음성 등 사용자 친화적인 형태로 출력<br> \* 외부 시스템(결제 시스템, 서빙 로봇)과 연동하기 위한 표준 API를 제공<br><br>(다이어그램)<br>[멀티모달 센서 모듈: LIDAR, 열화상 카메라, RGB 카메라, IMU] -\> (데이터 수집) -\> [공간 파악 모듈: 3D 맵 생성 및 업데이트, 객체 인지 및 추적] -\> (상황 정보 전달) -\> [LLM 기반 상호작용 모듈: 공간 맥락 이해, 자연어 대화, 의도 추론] -\> (판단 및 지시) -\> [행동/응답 모듈: 알림, 자율 판단, 임무 수행] -\> [출력/인터페이스 모듈: 디스플레이, 음성, 로봇 바디 연결] -\> (사용자/외부 시스템) |
| **2.3 주요 기능** | [사람 인지 및 감성적 응대]<br> \* 고객의 방문을 인지하고, 감성적 대화를 통해 메뉴 추천 및 주문을 접수<br><br>[3차원 공간 내 객체 추적 및 관리]<br> \* 현실적인 3D 맵을 생성하고 지속 업데이트<br> \* 천장 라이다를 통해 생성된 3D 공간에서 모든 고객과 사물의 위치를 정밀하게 추적<br><br>[주문 매칭 및 서빙 알림]<br> \* 고객이 자리에 앉으면 해당 위치와 주문 정보를 자동으로 매칭<br> \* 필요시, 서빙 로봇에게 정확한 위치 정보를 제공<br><br>[매장 환경 관리 및 위험 예측]<br> \* 고객이 쏟은 음료수나 방치된 가방과 같은 이상 상황을 자동으로 감지하고, 관리자에게 즉시 알림<br><br>[지능형 키오스크 역할]<br> \* 단순 명령 수행을 넘어 주변 환경 변화를 감지하고 자율적으로 판단<br> \* 사용자의 요구를 예측하고 지원하는 능동형 키오스크 역할을 수행 |
| **2.4 결과물 형상** | \* 공간지능 플랫폼이 적용된 무인 리테일 시스템을 구축하며, 이는 하드웨어 디바이스와 통합된 AI 소프트웨어 형태로 제공<br> \* **하드웨어** : 멀티모달 센서(LiDAR, 열화상 카메라, RGB 카메라 등)가 통합된 지능형 상호작용 디바이스<br> \* **소프트웨어** : 공간 파악(3D 맵핑, 객체 추적, 상황 인지, 위험 예측), LLM 기반 AI 상호작용, 서비스 로직 및 연동 API |
| **2.5 배포 방식** | \* 본 기술은 "공간지능 플랫폼"과 이를 활용한 "무인 리테일 운영 시스템"의 두 가지 형태로 배포<br><br>[공간지능 플랫폼]<br> \* 멀티모달 센서 (LiDAR, 열화상 카메라, RGB 카메라, IMU 등), 실시간 3D 맵 생성 및 업데이트, 객체 인지 및 정밀 추적 기능, 그리고 LLM(대규모 언어 모델) 기반의 감성형 AI 상호작용 부분으로 구성<br> \* 하드웨어 (지능형 상호작용 디바이스 및 3D 고정형 라이다 등) 형태로 제공<br> \* 핵심 기능들을 활용할 수 있도록 API를 제공하여 다양한 시스템과의 연동을 지원<br><br>[무인 리테일 운영 시스템]<br> \* 공간지능 플랫폼을 기반으로 하는 구체적인 적용 예시 중 하나로, 무인 리테일 환경에서의 고객 응대, 주문 매칭, 매장 관리 및 위험 예측 등의 기능을 제공<br> \* 수요처가 유연하게 커스터마이징하고 자체 시스템에 통합할 수 있도록 소스코드 형태로 배포 |

\-2-

-----

| | |
| :--- | :--- |
| **2.6 혁신적 요소** | [공간지능 기반의 통합 무인 리테일 시스템 구현]<br> \* 고객의 선택에 의해서만 작동하던 기존 시스템과 달리, 멀티모달센서기반의 지능형 상호작용 디바이스가 고객과 대화를 통해 고객 니즈를 파악하고, 음성 및 주변에 위치한 키오스크 등을 활용하여 맞춤형 메뉴를 제안함.<br> \* 첫 번째 단계로, 멀티모달센서기반 지능형 상호작용 디바이스와 고정형 라이다를 유/무인 혼합 매장 환경에 적용하는 것을 목표로 함. 주요 기능으로는 '메뉴 제안 및 실시간 주문 정보 처리', '고객의 제스처 인식' 및 '매장 내 이상 상황 및 위험 상황 감지' 등이 포함됨. 천장에 설치된 3D 고정형 라이다를 기반으로 실제 환경과 유사하게 구현된 고품질 3D 가상 공간은 관리도구를 통해 관리자에게 제공되며, 이를 통해 관리자는 직관적으로 매장의 상태를 파악할 수 있음.<br> \* 향후, 이 시스템을 2족·4족 로봇 바디에 적용하여 로봇이 메뉴 제안, 고객 위치 추적, 서빙, 자리 정리, 위험 대응까지 수행할 수 있는 완전 자율형 무인 매장 시스템으로 확장할 계획임. 이는 스마트 스토어, 고령자 케어, 안전 감시 등 다양한 산업군으로 확대할 수 있음 |
| **2.7 도전적 요소** | [다양한 분야로 확장 가능한 능동형 공간지능 시스템 개발]<br> \* 본 기술은 공간 전체를 실시간으로 인지하고 상황을 분석, 판단, 대응할 수 있는 능동형 공간지능 플랫폼을 구현하는 것을 목표로 함<br> \* 이를 위해, 현재 환경이 어떤 상황인지 추정하고, 목적 기반 추론에 따라 문제를 해결하는 agent 기술과 현실에 근접한 3D 가상환경을 실시간으로 사용자에게 제공하는 기술이 핵심임. 본 개발에서는 실시간 멀티모달 데이터 파이프라인을 구축하고, 강화학습 및 자기반성/자기평가에 대한 기술 확보뿐만 아니라 제품화가 가능한 수준으로 추론 정확도 향상 기술을 개발할 계획임. 또한 실제 환경과 유사한 가상 공간 모니터링 기술을 개발하여, 사용자가 매장의 상황을 직관적으로 파악할 수 있는 관리 도구를 개발할 계획임.<br> \* 향후 자율주행 또는 비행, 로봇과 같은 physical body와 연동 및 제어를 위해 공간지능 시스템과 physical body 제어기 사이의 행동 시나리오 트리 및 통신 프로토콜 설계 등과 같은 로봇 연동 및 표준화 기술 개발이 필요함. |

[붙임2] 구현제안서 양식(v1.0)

## 3\. 구현 방법 및 계획

| | |
| :--- | :--- |
| **3.1 구현 범위** | [세부업무 \#1: 공간 파악 모듈 개발]<br> \* 멀티모달 센서 데이터 수집 및 전처리<br> \* 이종 센서 데이터의 정밀 캘리브레이션 및 시점 동기화<br> \* 노이즈 제거 및 데이터 정합을 통한 고품질 융합 데이터 생성<br> \* 동적 환경에 대응하는 3D 공간 맵 생성 및 실시간 동기화<br> \* 다중 3D 라이다 기반의 공간 스캔 및 고정밀 3D 공간 데이터 생성<br> \* SLAM과 3D Gaussian Splatting을 결합하여 실시간으로 변하는 공간을 3D 맵에 즉각적으로 동기화<br> \* 공간 맥락 분석을 위한 3D 객체 탐지 및 추적<br> \* 멀티모달 융합 데이터에 시맨틱 분할 기술을 적용하여 3D 공간 내 객체를 정확하게 인지하고 분류<br> \* 고객의 동선과 객체의 상태 변화를 실시간으로 추적하여 행동 패턴 분석 정보 생성<br><br>[세부업무 \#2: LLM 기반 능동형 상호작용 및 서비스 로직 개발]<br> \* LLM 모델 연동 및 사용자 의도 추론<br> \* 공간 맥락 정보와 사용자의 음성/텍스트 입력을 통합하여 처리<br> \* 사용자의 명시적 명령뿐만 아니라, 비언어적 맥락에 기반한 잠재적 요구를 선제적으로 추론<br> \* 무인 리테일 특화 대화 로직 구현<br> \* 단순 응대를 넘어, 고객 맞춤형 추천, 프로모션 안내 등 구매 전환과 만족도 향상을 유도하는 서비스 중심 대화 로직 구현<br> \* 주문, 결제, 멤버십 연동 등 리테일 핵심 기능에 대한 대화형 인터페이스 개발<br> \* 상황 판단 기반의 자율 행동 결정 모듈 구현<br> \* LLM의 추론 결과를 바탕으로 구체적인 행동을 자율적으로 결정<br> \* 음식 서빙 위치 알림, 자리 정리 알림 등 서비스 알림 기능 개발<br><br>[세부업무 \#3: 무인 리테일 시스템 통합]<br> \* End-to-End 공간지능 시스템 구축<br> \* 센서 입력부터 공간 분석, LLM 추론, 행동 결정, 출력 인터페이스까지 모든 모듈을 유기적으로 연동하는 통합 파이프라인 설계<br> \* 실시간 데이터 처리를 위한 분산 컴퓨팅 및 최적화 수행<br> \* 핵심 리테일 시나리오 기반 시스템 통합 및 검증<br> \* 방문 고객 자동 인지 및 선제적 응대 → 좌석-주문 매칭 및 서빙 위치 연동 → 이상 상황(분실물, 오염 등) 감지 및 관리자 알림으로 이어지는 핵심 운영 시나리오를 자동화<br> \* 각 시나리오의 시스템 반응 정확성과 안정성을 집중적으로 테스트하고 검증<br> \* 고정형 공간지능 플랫폼 프로토타입 제작<br> \* 멀티모달 센서(LiDAR, 카메라 등)와 컴퓨팅 유닛, 디스플레이/스피커가 통합된 올인원(All-in-one) 하드웨어 플랫폼 설계 및 제작<br> \* 주변 환경 변화를 스스로 감지하고 자율적으로 판단하여 사용자의 요구를 예측하고 지원하는 능동형 공간지능 플랫폼 개발<br> \* 외부 시스템(결제 시스템, 서빙 로봇 등)과 연동하기 위한 표준 API를 제공 |
| **3.2 구현 계획** | [2025년 7월 (1개월차)] 공간지능 기반 무인 리테일 시스템 기초 설계<br> \* 프로젝트 요구사항 및 핵심 시나리오 정의<br> \* 시스템 아키텍처 및 개발 환경 설계<br> \* 데이터 수집 및 가공 계획 수립<br><br>[2025년 8월 (2개월차)] 공간지능 핵심 모듈 및 LLM 기반 상호작용 모듈 개발<br> \* 멀티모달 센서 데이터 수집, 동기화 및 융합 기초 기능 구현<br> \* 실시간 3D 공간 맵 생성 알고리즘 구현<br> \* 3D 공간 내 사람, 객체 인지 및 추적 기능 개발<br> \* LLM 기반 상호작용 및 사용자 의도 파악 시스템 구현<br> \* 기본 대화 구조 및 시나리오 검증<br><br>[2025년 9월 (3개월차)] 핵심 모듈 기능 고도화 및 무인 리테일 시나리오 통합<br> \* 공간 파악 모듈 및 LLM 상호작용 모듈 기능 고도화<br> \* 무인 리테일 시나리오 통합 및 초기 통합 시스템 구현<br> \* 핵심 시나리오 기반 능동형 공간지능 플랫폼 초기 구현<br> \* 중간 산출물(시연 동영상) 제출 및 평가 준비<br><br>[2025년 10월 (4개월차)] 시스템 안정화 및 최종 시제품 완성<br> \* 시스템 안정화 및 성능 검증<br> \* 능동형 공간지능 플랫폼 시제품 완성<br> \* 출력/인터페이스 모듈 완성<br> \* 최종 결과물 제출 및 발표/시연 준비 |
| **3.3 기술 스택** | [센서 융합 및 처리]<br> \* LIDAR 포인트 클라우드 처리 기술 (PCL(Point Cloud Library) 등)<br> \* 카메라 이미지 처리 기술 (OpenCV 등)<br> \* 센서 데이터 융합 기술<br> \* 이종 센서 캘리브레이션 기술<br><br>[공간 정보 생성]<br> \* ROS2, SLAM 알고리즘, 3D Gaussian Splatting, 객체 인지 알고리즘<br><br>[AI/LLM]<br> \* Python, PyTorch, LLM API (OpenAl, Gemini 등), 음성 처리 기술<br><br>[백엔드]<br> \* FastAPI/Flask (시스템 제어 및 API 제공)<br><br>[데이터 저장]<br> \* PostgreSQL (3D 맵 데이터, 주문 정보 등), Redis (실시간 캐싱)<br><br>[배포 환경]<br> \* Docker (컨테이너 기반 배포), 클라우드 컴퓨팅 서비스 |

[붙임2] 구현제안서 양식(v1.0)
\-4-

-----

## 4\. 파급효과

| | |
| :--- | :--- |
| **4.1 기술적 파급효과** | [공간지능 기반 상호작용 시스템의 패러다임 제시]<br> \* 본 기술은 공간 전체를 실시간으로 인지하고, 고객의 위치, 상태, 행동을 종합적으로 파악하여 능동적으로 판단하고 대응하는 지능형 공간지능 시스템임. 이는 단순한 자동화 기술을 넘어 인지, 판단, 대응이 하나로 통합된 플랫폼으로, 고객과 공간, 시스템 간의 연속적인 상호작용을 통해 리테일, 병원, 교육기관, 복지시설, 스마트홈, 스마트시티 등 다양한 물리적 공간에 적용 가능하다는 점에서 새로운 기술 패러다임을 제시함<br> \* 또한 서빙 로봇, 안내 로봇, 순찰 로봇 등 다양한 서비스 로봇이 외부 환경에 의존하지 않고 공간지능 플랫폼과 연동하여 보다 빠르게 구현 및 상용화될 수 있는 기술적 기반을 제공함.<br><br>[특허 출원 및 학술 논문 게재]<br> \* 본 기술은 고정형 라이다 기반의 공간지능 플랫폼과 멀티모달센서를 이용한 지능형 상호작용 디바이스로 구성되며, 각 모듈은 지식재산권 확보가 가능한 기술 요소를 포함하고 있음<br> \* 고객 맞춤형 자동 응대 알고리즘<br> \* 추론 정확도 향상을 위한 알고리즘<br> \* 공간 내 객체 상태 기반 이벤트 알림 및 대응 로직<br> \* 정적/동적 플랫폼 간 실시간 공간 맵 공유 및 업데이트 프로토콜<br> \* 본 시스템은 AI, 로보틱스, HCI(Human-Computer Interaction) 관련 국내외 저널에 논문 게재를 목표로 하고 있으며, 기술 고도화와 병행하여 논문 발표와 특허 출원을 동시에 추진할 계획임. |
| **4.2 사회·산업적 파급효과** | [다양한 응용 분야로의 확장 및 사회적 가치 실현]<br> \* 키오스크 이용 실태조사 발표에 따르면 소비자의 46.6%가 키오스크 이용 중 불편과 피해를 경험했다고 답함. 특히 노인 대다수는 복잡한 사용방식이나 작은 글씨 등으로 인해 디지털 서비스의 편리함을 누리지 못하고 있어 현행 시스템은 사용자 친화성이 부족한 실정임.<br> (표: 키오스크 이용 실태조사 (출처: 한국소비자원))<br> \* 공간지능 플랫폼은 대화를 통해 고객의 니즈 파악 및 메뉴를 제안하는 등, 고객의 사용 편의성을 극대화하였을 뿐만 아니라, 전 과정 무인화를 통해 매장 운영의 효율성 및 회전율을 높이고, 인건비 절감과 서비스 품질 표준화라는 효과를 기대할 수 있음.<br> \* 산업용 작업 로봇 및 산업 현장의 안전 관리 시장에서 활용이 가능할 뿐만 아니라, 최근 우크라이나 사태를 포함한 글로벌 분쟁 및 미국·중국 등 주요국의 국방 로봇 투입 계획에 따라, 방위 산업에서도 공간지능 기술 수요가 급증하고 있음. 이는 정찰, 폭발물 처리, 경비 로봇 등 다양한 국방용 로봇이 실시간 상황 판단과 안전 대응을 수행할 수 있는 기반이 되어, 국가 안보 역량을 강화하는 핵심 기술로 기여할 수 있음.<br><br>[비즈니스 모델화]<br> \* 본 기술은 하드웨어(지능형 상호작용 디바이스 및 3D 고정형 라이다 등) 형태로 제공할 예정임<br> \* 이 시스템은 B2B 대상 패키지 모델, API/SaaS 기반 서비스형 모델, 데이터 분석 기반 구독형 모델 등 다양한 비즈니스 방식으로 사업화가 가능함<br> \* 초기에는 식당, 카페 등 리테일 매장에 적용 가능한 솔루션으로 활용할 수 있으며, 후속 연구를 통해 이동형 로봇 플랫폼과 결합하면 주문 응대 외에도 물리적인 이동이나 작업(청소, 정리)을 수행할 수 있는 고도화 서비스로 확장 가능함 |

[붙임2] 구현제안서 양식(v1.0)
\-5-